{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78edd19a-b45a-4e9e-9d82-d4cd7d8951c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:05.781129Z",
     "iopub.status.busy": "2025-01-03T19:46:05.780899Z",
     "iopub.status.idle": "2025-01-03T19:46:06.823998Z",
     "shell.execute_reply": "2025-01-03T19:46:06.823489Z",
     "shell.execute_reply.started": "2025-01-03T19:46:05.781111Z"
    }
   },
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import json\n",
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049e2144-8535-4453-ad53-757bf928c104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.825019Z",
     "iopub.status.busy": "2025-01-03T19:46:06.824657Z",
     "iopub.status.idle": "2025-01-03T19:46:06.828120Z",
     "shell.execute_reply": "2025-01-03T19:46:06.827588Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.824998Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['HF_HOME'] = 'run/cache/'\n",
    "os.environ['GROQ_API_KEY'] = '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'\n",
    "api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f135eed9-4cfe-49c2-aa11-58b81f023da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.828967Z",
     "iopub.status.busy": "2025-01-03T19:46:06.828717Z",
     "iopub.status.idle": "2025-01-03T19:46:06.837515Z",
     "shell.execute_reply": "2025-01-03T19:46:06.837048Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.828946Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7319ba07-76e5-4352-8f03-b28cb15908f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.838552Z",
     "iopub.status.busy": "2025-01-03T19:46:06.838151Z",
     "iopub.status.idle": "2025-01-03T19:46:06.918236Z",
     "shell.execute_reply": "2025-01-03T19:46:06.917722Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.838522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7fb4c390e6c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields = [\"question\", \"text\", \"section\"],\n",
    "    keyword_fields = [\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f465a5b-4e12-4ceb-aa2f-23ccab26dcce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.919112Z",
     "iopub.status.busy": "2025-01-03T19:46:06.918844Z",
     "iopub.status.idle": "2025-01-03T19:46:06.959958Z",
     "shell.execute_reply": "2025-01-03T19:46:06.959498Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.919089Z"
    }
   },
   "outputs": [],
   "source": [
    "client = Groq(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b834fcad-d5ae-4ccb-affd-3c28a2e1887c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.961680Z",
     "iopub.status.busy": "2025-01-03T19:46:06.961406Z",
     "iopub.status.idle": "2025-01-03T19:46:06.964887Z",
     "shell.execute_reply": "2025-01-03T19:46:06.964338Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.961660Z"
    }
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {\n",
    "    'question': 3.0,\n",
    "    'section': 0.5,   \n",
    "    }\n",
    "    \n",
    "    results = index.search(\n",
    "        query = query,\n",
    "        filter_dict = {'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict = boost,\n",
    "        num_results = 5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24838b6-8b08-428a-81bd-3cfccd560e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.965796Z",
     "iopub.status.busy": "2025-01-03T19:46:06.965532Z",
     "iopub.status.idle": "2025-01-03T19:46:06.970757Z",
     "shell.execute_reply": "2025-01-03T19:46:06.970319Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.965776Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Only use the facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain answer, output NONE. \n",
    "    Do not Quote the CONTEXT in the answer.\n",
    "\n",
    "    QUESTION: {question}\n",
    "    CONTEXT: {context}\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section:{doc['section']}\\n question:{doc['question']}\\n text:{doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c527c1a-7bae-4055-aec3-315e95fb98f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:06.971598Z",
     "iopub.status.busy": "2025-01-03T19:46:06.971330Z",
     "iopub.status.idle": "2025-01-03T19:46:06.976888Z",
     "shell.execute_reply": "2025-01-03T19:46:06.976453Z",
     "shell.execute_reply.started": "2025-01-03T19:46:06.971574Z"
    }
   },
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "    #\n",
    "    # Required parameters\n",
    "    #\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query,\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "\n",
    "    #\n",
    "    # Optional parameters\n",
    "    #\n",
    "\n",
    "    # Controls randomness: lowering results in less random completions.\n",
    "    # As the temperature approaches zero, the model will become deterministic\n",
    "    # and repetitive.\n",
    "    temperature=0.5,\n",
    "\n",
    "    # The maximum number of tokens to generate. Requests can use up to\n",
    "    # 32,768 tokens shared between prompt and completion.\n",
    "    max_tokens=1024,\n",
    "\n",
    "    # Controls diversity via nucleus sampling: 0.5 means half of all\n",
    "    # likelihood-weighted options are considered.\n",
    "    top_p=1,\n",
    "\n",
    "    # A stop sequence is a predefined or user-specified text string that\n",
    "    # signals an AI to stop generating content, ensuring its responses\n",
    "    # remain focused and concise. Examples include punctuation marks and\n",
    "    # markers like \"[end]\".\n",
    "    stop=None,\n",
    "\n",
    "    # If set, partial message deltas will be sent.\n",
    "    stream=False,\n",
    "    )\n",
    "\n",
    "    # Print the completion returned by the LLM.\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42729322-65f8-4be3-b2ea-84c978b254bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:42.821809Z",
     "iopub.status.busy": "2025-01-03T19:46:42.821478Z",
     "iopub.status.idle": "2025-01-03T19:46:42.825104Z",
     "shell.execute_reply": "2025-01-03T19:46:42.824483Z",
     "shell.execute_reply.started": "2025-01-03T19:46:42.821787Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"The course has already started, can I still enroll?\"\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c1398a3-96df-4d9d-8a6d-cb858101524a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:46:47.898538Z",
     "iopub.status.busy": "2025-01-03T19:46:47.898227Z",
     "iopub.status.idle": "2025-01-03T19:46:50.845554Z",
     "shell.execute_reply": "2025-01-03T19:46:50.844978Z",
     "shell.execute_reply.started": "2025-01-03T19:46:47.898516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, you're still eligible to submit the homeworks even if you don't register after the start date, but be aware of the deadlines for turning in the final projects.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bdbba16-1039-4653-96fe-984e5300bb12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T19:47:20.444717Z",
     "iopub.status.busy": "2025-01-03T19:47:20.444365Z",
     "iopub.status.idle": "2025-01-03T19:47:22.233391Z",
     "shell.execute_reply": "2025-01-03T19:47:22.232781Z",
     "shell.execute_reply.started": "2025-01-03T19:47:20.444694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NONE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"How can I run kafka?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a8889-140f-4820-ac3b-13c175b81ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0a21a-ef53-40b5-ac19-7428db76073c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00b8ec-8773-41db-aae3-3aeaf5ae1106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e815fc-8d67-4dfc-bdb6-9948ea2af407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986e47c-207c-4a64-8f4c-7da0e82361fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
